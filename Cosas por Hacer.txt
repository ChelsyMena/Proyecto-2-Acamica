- (ya) Eliminar Outliers usando IQR / 3std - Nos quedamos con el que menos bote, podemos separar 
- (ya) Buscar duplicados, titulo y descripción, y precio... si todo igual dejar una instancia, si precio cambia dejar ultimo
- (ya) Verificar que no falten baños en casa, ph, apto. Despues de elegir esos 3.
- (ya) Encoding para tipo de propiedad (Casa, Apto, PH)
- (ya) Escalar las superficies
- (ya) Poner Promedios de lat y lon por barrio en NAs

______________________________________________________________________

- (ya) Modelos avanzados: Polynomial Features, Boosting
    - Train Test Split, Grid Search y Cross Validation (n_folds = 5) a cada uno
        - Dataset sin outliers, escalado y encodeado, eliger mejor de cada uno
        
- (ya) Modelo del P1: Arbol de Decisión 
    Valeria: modeldt = DecisionTreeRegressor(max_depth = 14, random_state = 42)
    Chelsy: modeldt = DecisionTreeRegressor(max_depth = 30, random_state = 7)
     NOS QUEDAMOS CON max_depth = 11


Ideas Challenge
- (ya) Hacer clustering por barrio y ponerles el centroide de acuerdo a lat y lon, dibujar poligonos y centroides sobre un mapa

Preguntas
- (ya, tampoco sirvió) La data queda mejor antes de PCA, por que? podemos hacer PCA por segmentos: 
  Juntar sup cubierta y total en un PC, rooms bedrooms and bathrooms en otro, lat y lon en otro...
  Es necesario meter el encoding en el PCA?

  _____________________________________________________________________________________________________

  - Punto B, hay atributos de estos modelos que no estamos tocando, como la eficiencia de cada paso o algo asi?
  - Punto C, justificar todo lo de arriba
  - Comentar comentar comentar y explicar, especialmente las funciones. Agregar docstring
  - Organizar bien, PCA donde quedó al fin? Poner mejores títulos
  - Eliminar celdas redundantes de importaciones y lecturas de csv
  - Exportar mapa a html a ver si funciona afuera